#!/usr/bin/env python3
import os
import subprocess
import shlex
import hashlib
from pathlib import Path
import json



def hash_file(filename: Path) -> str:
    """Generate SHA-1 hash of a file
    """
    m = hashlib.sha1()
    block_size = 65536
    with open(filename, 'rb') as fp:
        while True:
            data = fp.read(block_size)
            if not data:
                break
            m.update(data)
    return m.hexdigest()


def hash_files(*filenames: Path) -> tuple[dict[Path, str], str]:
    """Generate a combined SHA-1 hash from multiple files

    The combined hash is generated by XORing the SHA-1 hashes of each file
    and then hashing the result.

    If no files are provided, the combined result will be the SHA-1 hash of an
    empty string.

    Returns:
        - **hash_dict**: A dictionary mapping each filename to its SHA-1 hash
        - **combined_hash**: The combined SHA-1 hash of all files
    """
    m = hashlib.sha1()
    combined = 0
    hash_dict: dict[Path, str] = {}
    for filename in filenames:
        file_hash = hash_file(filename)
        hash_dict[filename] = file_hash
        int_val = int(file_hash, 16)
        combined ^= int_val
    if combined != 0:
        combined_hex = hex(combined)[2:]
        m.update(combined_hex.encode('UTF-8'))
    return hash_dict, m.hexdigest()


def get_git_commit(src_dir: Path) -> str:
    """Get the latest commit hash for a directory within a git repository
    """
    cmd_str = f'git log --pretty=tformat:"%h" -n1 {src_dir}'
    r = subprocess.run(shlex.split(cmd_str), capture_output=True)
    h = r.stdout.splitlines()[0]
    assert len(h) == 7
    return h.decode('UTF-8')


def write_build_meta(
    json_filename: Path,
    mpy_root: Path,
    src_dir: Path|None,
    **extra_meta: dict[str, str],
) -> None:
    """Write build metadata to a JSON file

    The build metadata includes:

    .. code-block:: json

        {
            "mpy_commit": "abcdefg",
            "file_checksum": "1234567890abcdef",
            "file_checksums": {
                "src/file1.py": "1234567890abcdef",
                "src/file2.py": "abcdef1234567890"
            }
        }

    Where:

    - **mpy_commit**: The latest commit hash of the MicroPython repository
    - **file_checksum**: The SHA-1 hash of all Python files in the source directory
    - **file_checksums**: A dictionary mapping each Python file to its SHA-1 hash
    - **extra_meta**: Additional metadata to include in the JSON file


    Args:
        json_filename: Path to the JSON file to write
        mpy_root: Path to the MicroPython root directory
        src_dir: Path to the source directory (or None)
        **extra_meta: Additional metadata to include in the JSON file
    """
    mpy_commit = get_git_commit(mpy_root)
    if src_dir is None:
        py_hash = None
        file_checksums = {}
    else:
        py_files = [p for p in src_dir.glob('**/*.py') if p.is_file()]
        py_hashes, py_hash = hash_files(*py_files)
        file_checksums = {str(k): v for k, v in py_hashes.items()}
    data = {
        'mpy_commit': mpy_commit,
        'file_checksum': py_hash,
        'file_checksums': file_checksums,
    }
    data.update(extra_meta)
    json_filename.write_text(json.dumps(data, indent=2))



if __name__ == '__main__':
    import argparse
    p = argparse.ArgumentParser()
    p.add_argument('--mpy-root', required=True)
    p.add_argument('--src-dir')
    p.add_argument(
        '-e', '--extra-meta',
        action='append',
        nargs='*',
        help='Extra metadata to include. Formatted as key=value. Multiple values can be provided, separated by commas.',
    )
    p.add_argument('json_filename')
    args = p.parse_args()

    args.mpy_root = Path(args.mpy_root)
    if args.src_dir is not None:
        args.src_dir = Path(args.src_dir)
    args.json_filename = Path(args.json_filename)

    def parse_meta_item(item: str|list[str]) -> dict[str, str]:
        if isinstance(item, list):
            return {
                k: v for i in item
                    for k, v in parse_meta_item(i).items()
            }
        if ',' in item:
            return {
                k: v for i in item.split(',')
                    for k, v in parse_meta_item(i).items()
            }
        if '=' in item:
            key, value = item.split('=')
            return {key: value}
        raise ValueError(f'Invalid format for extra metadata: {item}')

    extra_meta = {}
    env_meta = os.environ.get('EXTRA_BUILD_META_OPTS')
    if env_meta is not None:
        extra_meta.update(parse_meta_item(env_meta))
    if args.extra_meta is not None:
        for item in args.extra_meta:
            extra_meta.update(parse_meta_item(item))

    write_build_meta(
        json_filename=args.json_filename,
        mpy_root=args.mpy_root,
        src_dir=args.src_dir,
        **extra_meta,
    )
